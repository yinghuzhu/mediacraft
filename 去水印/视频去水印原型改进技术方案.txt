
1. 绪论
本文档旨在对现有的视频去水印 Python 脚本原型进行关键性升级。当前原型存在**水印位置写死（灵活性差）和修复算法效果不佳（质量有限）**两大核心问题。本方案将提出并详细阐述一套切实可行的技术实现路径，以解决上述问题，为后续的产品化开发奠定坚实的基础。
2. 核心问题与解决方案
2.1. 问题一：灵活性差
现状: 水印坐标 (1080, 20, 1260, 70) 被硬编码在程序中，脚本只能处理固定版式的视频。
解决方案: 实现交互式水印区域选择。在处理开始前，程序将展示视频的第一帧，并允许用户使用鼠标交互式地、精准地框选出一个或多个需要移除的水印区域。
2.2. 问题二：处理效果有限
现状: 使用 cv2.INPAINT_TELEA 算法进行修复。该算法速度快，但原理是基于边界像素的扩散，在纹理复杂的背景上会产生明显的模糊、涂抹和失真。
解决方案: 集成基于深度学习的 AI 修复模型。我们将采用一个预训练好的 AI 模型（如 LaMa 模型），它能够理解图像的上下文和结构，生成语义上合理且视觉上无痕的填充内容，效果远超传统算法。
3. 技术实现详解
3.1. 步骤一：实现交互式水印选择
我们将使用 OpenCV 的鼠标事件处理功能 cv2.setMouseCallback 来捕获用户的操作。
实现逻辑:
读取视频的第一帧图像。
在一个窗口中显示该帧。
设置一个鼠标回调函数，用于监听鼠标的按下、移动和抬起事件。
用户按下鼠标左键时，记录起始点坐标。
用户拖动鼠标时，在界面上实时绘制一个矩形以提供视觉反馈。
用户松开鼠标左键时，记录矩形的最终坐标，并将其保存到一个列表中。用户可以重复此操作以选择多个水印。
用户完成所有选择后，按下一个指定按键（如 Enter 或 c）来确认选择，程序将带着这些坐标进入下一步。
伪代码实现:
Python
import cv2

# --- 全局变量 ---
selected_rois = []  # 存储所有选择的矩形区域 (x, y, w, h)
is_drawing = False
start_point = (-1, -1)
current_frame_copy = None

def mouse_callback(event, x, y, flags, param):
    """鼠标回调函数，用于处理绘制矩形的操作"""
    global start_point, is_drawing, current_frame_copy, selected_rois

    if event == cv2.EVENT_LBUTTONDOWN:
        start_point = (x, y)
        is_drawing = True
    
    elif event == cv2.EVENT_MOUSEMOVE:
        if is_drawing:
            # 在副本上绘制，避免永久性地画在原图上
            temp_frame = current_frame_copy.copy()
            cv2.rectangle(temp_frame, start_point, (x, y), (0, 255, 0), 2)
            cv2.imshow("Select Watermark - Press 'c' to confirm, 'r' to reset", temp_frame)

    elif event == cv2.EVENT_LBUTTONUP:
        is_drawing = False
        end_point = (x, y)
        # 确保坐标顺序正确 (x1 < x2, y1 < y2)
        x1, y1 = min(start_point[0], end_point[0]), min(start_point[1], end_point[1])
        x2, y2 = max(start_point[0], end_point[0]), max(start_point[1], end_point[1])
        
        # 保存矩形并绘制在永久副本上
        selected_rois.append((x1, y1, x2-x1, y2-y1))
        cv2.rectangle(current_frame_copy, (x1, y1), (x2, y2), (0, 0, 255), 2)
        cv2.imshow("Select Watermark - Press 'c' to confirm, 'r' to reset", current_frame_copy)

def select_watermark_area(video_path):
    """
    打开视频第一帧，让用户选择水印区域
    返回: 一个包含所有矩形坐标的列表 [(x, y, w, h), ...]
    """
    global current_frame_copy, selected_rois
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Error: Could not open video.")
        return None
    
    ret, frame = cap.read()
    if not ret:
        print("Error: Could not read the first frame.")
        return None
    cap.release()
    
    current_frame_copy = frame.copy()
    window_name = "Select Watermark - Press 'c' to confirm, 'r' to reset"
    cv2.namedWindow(window_name)
    cv2.setMouseCallback(window_name, mouse_callback)
    
    print("请在图片上拖动鼠标选择水印区域。")
    print("可以选择多个区域。完成后按 'c' 键确认。")
    print("如果选错，按 'r' 键重置所有选择。")

    while True:
        cv2.imshow(window_name, current_frame_copy)
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('c'):  # 'c' for confirm
            break
        elif key == ord('r'): # 'r' for reset
            current_frame_copy = frame.copy()
            selected_rois = []
            print("选择已重置，请重新选择。")

    cv2.destroyAllWindows()
    
    print(f"已选择 {len(selected_rois)} 个区域: {selected_rois}")
    return selected_rois

3.2. 步骤二：集成 AI 修复模型
我们将使用一个强大的开源模型 LaMa (Large Mask Inpainting)。使用它需要 PyTorch 环境。
集成逻辑:
环境准备: 确保已安装 torch 和 torchvision。下载预训练的 LaMa 模型权重文件 (.pth)。
模型加载: 在主程序开始时，加载 LaMa 模型并设置为评估模式 (model.eval())。
创建统一的修复函数: 创建一个函数 inpaint_with_ai，它接收原始图像和蒙版 (Mask) 作为输入。
数据预处理: 在函数内部，将 OpenCV 的 BGR numpy 图像转换为 PyTorch Tensor，并进行归一化等模型需要的预处理。
执行模型推理: 将处理后的图像和蒙版输入 AI 模型，得到修复后的图像 Tensor。
数据后处理: 将模型输出的 Tensor 转换回 OpenCV 的 numpy 图像格式，以便后续写入视频。
伪代码实现 (这部分假设你已经有 LaMa 模型的代码结构):
Python
# --- 模型加载 (在主程序开始时执行一次) ---
# from saic_vision.training.modules import FFCResNetGenerator
# import torch

# def load_ai_model(model_path):
#     """加载预训练的 LaMa 模型"""
#     # 此处为加载模型的示例代码，具体取决于你使用的 LaMa 实现
#     # model = FFCResNetGenerator(...) 
#     # checkpoint = torch.load(model_path, map_location='cpu')
#     # model.load_state_dict(checkpoint['state_dict'])
#     # model.eval()
#     # return model
#
# # ai_model = load_ai_model("path/to/your/big-lama.pth")
# # print("AI 模型加载成功！")

# --- AI 修复函数 ---
def inpaint_with_ai(frame, mask, ai_model):
    """
    使用 AI 模型进行图像修复
    
    注意: 这是一个高度简化的伪代码，实际实现需要严格遵循
    你所使用的 AI 模型库的预处理和后处理要求。
    """
    # 1. 预处理
    # - BGR to RGB
    # - a. 将 OpenCV frame (H, W, C) numpy uint8 转换为 (C, H, W) float32 Tensor
    # - b. 将 mask (H, W) numpy uint8 转换为 (1, H, W) float32 Tensor
    # - c. 对图像和蒙版进行归一化 (e.g., to [0, 1] or [-1, 1])
    # - d. 将数据移到 GPU (if available): .to(device)
    # image_tensor = preprocess(frame)
    # mask_tensor = preprocess_mask(mask)

    # with torch.no_grad():
    #     # 2. 执行推理
    #     inpainted_tensor = ai_model(image_tensor, mask_tensor)
    
    # 3. 后处理
    # - a. 将输出的 tensor 转换回 numpy 数组
    # - b. 反归一化，将像素值恢复到 [0, 255]
    # - c. RGB to BGR
    # - d. 转换数据类型为 uint8
    # result_frame = postprocess(inpainted_tensor)
    
    # return result_frame

    # --- 临时的替代实现，直到你集成真正的模型 ---
    # 你可以暂时使用效果稍好的 cv2.INPAINT_NS 进行测试
    print("正在使用 cv2.INPAINT_NS (非AI) 进行修复...")
    return cv2.inpaint(frame, mask, 3, cv2.INPAINT_NS)

注意: 真正的 AI 模型集成涉及具体的库依赖。上面的伪代码旨在说明逻辑流程。您需要找到一个 LaMa 的 GitHub 仓库，并遵循其 inference.py 示例来编写 inpaint_with_ai 函数。
4. 完整的原型代码框架
现在，我们将上述两个解决方案整合到您的原始代码流中。
Python
import cv2
import numpy as np
import moviepy.editor as mp
# 伪代码: 假设 AI 模型相关库已导入
# from ai_model_utils import load_ai_model, inpaint_with_ai

# --- 1. 初始化和配置 ---
input_video = "/path/to/your/input.mp4"
output_video = "/path/to/your/output.mp4"
temp_video = "/path/to/your/temp.mp4"

# --- [可选] 加载 AI 模型 (如果使用) ---
# ai_model = load_ai_model("path/to/model.pth")


# --- 2. 交互式选择水印区域 (关键改进点 1) ---
# 该函数在上面 3.1 节已定义
selected_rois = select_watermark_area(input_video)

if not selected_rois:
    print("没有选择任何水印区域，程序退出。")
    exit()

# --- 3. 视频去水印处理 ---
cap = cv2.VideoCapture(input_video)
fourcc = cv2.VideoWriter_fourcc(*"mp4v")
fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
out = cv2.VideoWriter(temp_video, fourcc, fps, (width, height))
frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

print(f"开始处理视频，总帧数: {frame_count}")

# 创建一个静态蒙版，因为水印位置在整个视频中是固定的
# 这个蒙版将在所有帧上重复使用，以提高效率
static_mask = np.zeros((height, width), dtype=np.uint8)
for (x, y, w, h) in selected_rois:
    cv2.rectangle(static_mask, (x, y), (x+w, y+h), 255, -1)

for i in range(frame_count):
    ret, frame = cap.read()
    if not ret:
        break

    # --- 使用高级修复算法 (关键改进点 2) ---
    # inpainted_frame = inpaint_with_ai(frame, static_mask, ai_model) # 使用AI模型
    inpainted_frame = cv2.inpaint(frame, static_mask, 3, cv2.INPAINT_NS) # 或者使用OpenCV的NS算法

    out.write(inpainted_frame)
    if i % 100 == 0:
        print(f"已处理帧 {i}/{frame_count}")

print("视频内容处理完成。")
cap.release()
out.release()


# --- 4. 合并音频 ---
print("正在合并音频轨道...")
try:
    video_clip = mp.VideoFileClip(temp_video)
    original_audio = mp.VideoFileClip(input_video).audio
    
    final_clip = video_clip.set_audio(original_audio)
    final_clip.write_videofile(output_video, codec="libx264", audio_codec="aac")
    print(f"✅ 完成！输出文件: {output_video}")
except Exception as e:
    print(f"Error merging audio: {e}")
    print(f"无音频的视频文件已保存在: {temp_video}")


5. 下一步建议
在完成这个功能更强大的原型后，下一步的优化方向可以包括：
性能优化:
将 AI 模型推理部分放到 GPU 上运行，会带来数量级的速度提升。
如果水印是完全不透明的，可以先用 AI 修复第一帧的水印区域，然后将修复好的“背景补丁”缓存起来。在后续的帧中，如果背景变化不大，可以直接用这个补丁覆盖，而无需每帧都运行 AI 模型，极大提高效率。
处理动态水印: 这是更高级的挑战。需要结合目标检测和跟踪算法，在视频的每一帧中自动定位水印，生成动态蒙版。
构建用户界面: 将此后端逻辑封装，并通过 FastAPI 或 Flask 等框架提供 API 接口，然后开发一个前端界面（Web 或桌面应用），实现一个完整的产品雏形。